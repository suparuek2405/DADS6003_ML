{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suparuek2405/DADS6003_ML/blob/main/Multivariate_linear_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJKnfPH8F1nU"
      },
      "source": [
        "## Batch Gradient descent (Multiple linear regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9pYLiXogGD66"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jDcwoJv8F0jb"
      },
      "outputs": [],
      "source": [
        "def cost_function(theta, x, y, N):\n",
        "  y_hat = x.dot(theta)\n",
        "  c = (1/N)*np.sum((y_hat-y)**2)\n",
        "  return c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DaXAkGO2GC-j"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(alpha, x, y, ep=0.001, max_iter=10000):\n",
        "  converged = False\n",
        "  iter = 0\n",
        "  N = x.shape[0] # number of samples\n",
        "  print(\"Num of data = \",N)\n",
        "\n",
        "  # initial theta\n",
        "  theta =  np.random.random((x.shape[1],1))\n",
        "  print(\"Init theta.shape = \",theta.shape)\n",
        "\n",
        "  # total error, J(theta)\n",
        "  J = cost_function(theta, x, y, N)\n",
        "  print(\"First J = \",J)\n",
        "\n",
        "  # Iterate Loop\n",
        "  while not converged:\n",
        "\n",
        "    y_hat = x.dot(theta)\n",
        "    diff = y_hat - y\n",
        "    grad = x.T.dot(diff)\n",
        "\n",
        "    theta = theta - alpha * (1/N) * (grad)\n",
        "\n",
        "    assert theta.shape == (3,1) #This line makes sure that the shape of theta is still be the same.\n",
        "\n",
        "    # error\n",
        "    J2 = cost_function(theta, x, y, N)\n",
        "\n",
        "    if abs(J-J2) <= ep:\n",
        "        print(\"       Converged, iterations: \", iter, \"/\", max_iter)\n",
        "        converged = True\n",
        "\n",
        "    J = J2   # update error s\n",
        "    iter += 1  # update iter\n",
        "\n",
        "    if iter == max_iter:\n",
        "        print('       Max iterations exceeded!')\n",
        "        converged = True\n",
        "\n",
        "  #print(\"End converged iter = \",iter)\n",
        "  return theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7YHdEgEGSXS",
        "outputId": "69849fd6-7eaa-4011-ecf4-8269ca331bd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start main\n",
            "(3, 3)\n",
            "(3, 1)\n",
            "Num of data =  3\n",
            "Init theta.shape =  (3, 1)\n",
            "First J =  1.2375173175181602\n",
            "       Converged, iterations:  363715 / 1000000\n",
            "Theta =  [[ 7.]\n",
            " [15.]\n",
            " [-6.]]\n",
            "y predict =  [[13.]]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "  x = np.array([[0,1,],[2,6],[3,8]]) #x1, x2\n",
        "  y = np.array([1,1,4])\n",
        "  x_b = np.c_[np.ones((x.shape[0],1)),x]\n",
        "\n",
        "  print(\"start main\")\n",
        "  print(x_b.shape)\n",
        "  y = y.reshape(-1,1)\n",
        "  print(y.shape)\n",
        "\n",
        "  alpha = 0.01 # learning rate\n",
        "  #Training process\n",
        "  theta = gradient_descent(alpha, x_b, y, ep=0.00000000000001, max_iter=1000000)\n",
        "  print (\"Theta = \", theta)\n",
        "\n",
        "  #predict trainned x\n",
        "  xtest = np.array([[4,9]])\n",
        "  xtest_b = np.c_[np.ones((xtest.shape[0],1)),xtest]\n",
        "  y_p = xtest_b.dot(theta)\n",
        "  print(\"y predict = \",y_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zrc4L9kT2_q"
      },
      "source": [
        "## Stochastic GD from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "ZUlIgh8gGy16"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "def stochastic_gradient_descent(alpha, x, y, ep=0.001, max_iter=10000, decay_rate=0.01):\n",
        "  converged = False\n",
        "  iter = 0\n",
        "  N = x.shape[0] # number of samples\n",
        "  print(\"Num of data = \",N)\n",
        "\n",
        "  # initial theta\n",
        "  theta =  np.random.random((x.shape[1],1))\n",
        "  print(\"Init theta.shape = \",theta.shape)\n",
        "\n",
        "  # total error, J(theta)\n",
        "  J = cost_function(theta, x, y, N)\n",
        "  print(\"First J = \",J)\n",
        "\n",
        "  # Iterate Loop\n",
        "  while not converged:\n",
        "    # Learning rate decay\n",
        "    current_alpha = alpha / (1 + decay_rate * iter)\n",
        "\n",
        "    permutation = np.random.permutation(N)\n",
        "    x_shuffled = x[permutation]\n",
        "    y_shuffled = y[permutation]\n",
        "    for i in range(N):\n",
        "      y_hat = x[i:i+1].dot(theta)\n",
        "      diff = y_hat - y[i:i+1]\n",
        "      grad = x[i:i+1].T.dot(diff)\n",
        "\n",
        "      theta = theta - alpha * grad\n",
        "\n",
        "      assert theta.shape == (3,1)\n",
        "\n",
        "    # error\n",
        "    J2 = cost_function(theta, x, y, N)\n",
        "\n",
        "    if abs(J-J2) <= ep:\n",
        "      print(\"       Converged, iterations: \", iter, \"/\", max_iter)\n",
        "      print(f\"       The last learning rate = {current_alpha}\")\n",
        "      converged = True\n",
        "\n",
        "    J = J2\n",
        "    iter += 1\n",
        "\n",
        "    if iter == max_iter:\n",
        "      print('       Max iterations exceeded!')\n",
        "      converged = True\n",
        "\n",
        "  return theta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPwB5eEvVjPw",
        "outputId": "04218981-7692-45ce-e8ee-166bd37b2120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start main\n",
            "(3, 3)\n",
            "(3, 1)\n",
            "Num of data =  3\n",
            "Init theta.shape =  (3, 1)\n",
            "First J =  1.663418807945673\n",
            "       Converged, iterations:  79414 / 1000000\n",
            "       The last learning rate = 1.2576401639962775e-05\n",
            "Theta =  [[ 7.]\n",
            " [15.]\n",
            " [-6.]]\n",
            "y predict =  [[13.]]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "  x = np.array([[0,1,],[2,6],[3,8]]) #x1, x2\n",
        "  y = np.array([1,1,4])\n",
        "  x_b = np.c_[np.ones((x.shape[0],1)),x]\n",
        "\n",
        "  print(\"start main\")\n",
        "  print(x_b.shape)\n",
        "  y = y.reshape(-1,1)\n",
        "  print(y.shape)\n",
        "\n",
        "  alpha = 0.01 # learning rate\n",
        "  #Training process\n",
        "  theta = stochastic_gradient_descent(alpha, x_b, y, ep=0.000000000001, max_iter=1000000, decay_rate=0.01)\n",
        "  print (\"Theta = \", theta)\n",
        "\n",
        "  #predict trainned x\n",
        "  xtest = np.array([[4,9]])\n",
        "  xtest_b = np.c_[np.ones((xtest.shape[0],1)),xtest]\n",
        "  y_p = xtest_b.dot(theta)\n",
        "  print(\"y predict = \",y_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1Q64oGaaqHs"
      },
      "source": [
        "## Stochastic GD with SKlearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DG6WLJpCas7K",
        "outputId": "57a7136e-8ccf-4be9-932d-c78ce68d7d6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.07]  ,  [0.14 0.33]\n",
            "y predict =  [3.6]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDRegressor\n",
        "\n",
        "model = SGDRegressor(learning_rate='adaptive', eta0=0.01, penalty=None)\n",
        "x = np.array([[0,1,],[2,6],[3,8]]) #x1, x2\n",
        "y = np.array([1,1,4])\n",
        "model.fit(x, y)\n",
        "print(model.intercept_,\" , \",model.coef_)\n",
        "\n",
        "xtest = np.array([[4,9]])\n",
        "y_p = model.predict(xtest)\n",
        "print(\"y predict = \",y_p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v1uQg3Aexy6"
      },
      "source": [
        "## Mini-batch GD (size = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ptesBb2Qe1Gc"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNa0Si3jAqJwqOfHHlCFfbH",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
